"""
ğŸ§  BERT ëª¨ë¸ êµ¬í˜„
ê°•ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì™„ì „í•œ BERT ì‹œìŠ¤í…œ

FastBERT: ê³ ì† ì¶”ë¡ ì„ ìœ„í•œ ìµœì í™”ëœ ëª¨ë¸
ReliableBERT: ì‹ ë¢°ì„± í–¥ìƒì„ ìœ„í•œ ê²€ì¦ ì‹œìŠ¤í…œ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional, Tuple, Any
import time
import logging
from dataclasses import dataclass
import numpy as np

try:
    from .tokenizer import KoreanTokenizer, TokenizationResult
    from .embedding import ContextualEmbedding, EmbeddingResult
    from .attention import MultiHeadAttention, AttentionResult
except ImportError:
    from tokenizer import KoreanTokenizer, TokenizationResult
    from embedding import ContextualEmbedding, EmbeddingResult
    from attention import MultiHeadAttention, AttentionResult

logger = logging.getLogger(__name__)

@dataclass
class BERTOutput:
    """BERT ëª¨ë¸ ì¶œë ¥ ê²°ê³¼"""
    last_hidden_state: torch.Tensor
    pooler_output: torch.Tensor
    attention_weights: List[torch.Tensor]
    hidden_states: List[torch.Tensor]
    processing_time: float
    confidence_scores: Dict[str, float]
    government_predictions: Optional[Dict[str, float]] = None

class BERTLayer(nn.Module):
    """
    ğŸ”— BERT ë ˆì´ì–´ 
    ì–´í…ì…˜ + í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬
    """
    
    def __init__(self, d_model: int = 768, num_heads: int = 12, 
                 d_ff: int = 3072, dropout: float = 0.1):
        super().__init__()
        
        # ì…€í”„ ì–´í…ì…˜
        self.self_attention = MultiHeadAttention(d_model, num_heads, dropout)
        
        # í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬
        self.feed_forward = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_ff, d_model),
            nn.Dropout(dropout)
        )
        
        # ë ˆì´ì–´ ì •ê·œí™”
        self.layer_norm = nn.LayerNorm(d_model)
        
    def forward(self, hidden_states: torch.Tensor, 
                attention_mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """BERT ë ˆì´ì–´ ìˆœì „íŒŒ"""
        # ì…€í”„ ì–´í…ì…˜
        attention_result = self.self_attention(
            hidden_states, hidden_states, hidden_states, attention_mask
        )
        
        # í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ + ì”ì°¨ ì—°ê²°
        ff_output = self.feed_forward(attention_result.output)
        output = self.layer_norm(ff_output + attention_result.output)
        
        return output, attention_result.attention_weights

class FastBERT(nn.Module):
    """
    âš¡ ê³ ì† BERT ëª¨ë¸
    íš¨ìœ¨ì ì¸ ì¶”ë¡ ì„ ìœ„í•œ ìµœì í™”ëœ êµ¬í˜„
    """
    
    def __init__(
        self,
        vocab_size: int = 30000,
        d_model: int = 768,
        num_layers: int = 12,
        num_heads: int = 12,
        d_ff: int = 3072,
        max_length: int = 512,
        dropout: float = 0.1
    ):
        super().__init__()
        
        self.config = {
            'vocab_size': vocab_size,
            'd_model': d_model,
            'num_layers': num_layers,
            'num_heads': num_heads,
            'max_length': max_length
        }
        
        # í† í¬ë‚˜ì´ì €
        self.tokenizer = KoreanTokenizer(max_length=max_length)
        
        # ì‹¤ì œ ì–´íœ˜ í¬ê¸°ë¥¼ í† í¬ë‚˜ì´ì €ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        actual_vocab_size = len(self.tokenizer.vocab)
        
        # ì„ë² ë”© ë ˆì´ì–´
        self.embeddings = ContextualEmbedding(
            vocab_size=actual_vocab_size,
            d_model=d_model,
            max_length=max_length,
            dropout=dropout
        )
        
        # BERT ë ˆì´ì–´ë“¤
        self.layers = nn.ModuleList([
            BERTLayer(d_model, num_heads, d_ff, dropout)
            for _ in range(num_layers)
        ])
        
        # í’€ë§ ë ˆì´ì–´ (ë¬¸ì¥ í‘œí˜„ì„ ìœ„í•œ [CLS] í† í° ì²˜ë¦¬)
        self.pooler = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.Tanh()
        )
        
        # ì •ë¶€ ì§ì±… ë¶„ë¥˜ í—¤ë“œ
        self.government_classifier = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, 10)  # 10ê°œ ì£¼ìš” ì •ë¶€ ì§ì±…
        )
        
        # ì¶”ì²œ ë¶„ë¥˜ í—¤ë“œ
        self.recommendation_classifier = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, 3)  # ê°•ë ¥ì¶”ì²œ/ì¶”ì²œ/ë¹„ì¶”ì²œ
        )
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self.apply(self._init_weights)
        
        logger.info(f"âš¡ FastBERT ì´ˆê¸°í™” ì™„ë£Œ - ë ˆì´ì–´: {num_layers}, ì°¨ì›: {d_model}")
    
    def _init_weights(self, module):
        """ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
        if isinstance(module, nn.Linear):
            nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                nn.init.zeros_(module.bias)
        elif isinstance(module, nn.LayerNorm):
            nn.init.ones_(module.weight)
            nn.init.zeros_(module.bias)
    
    def forward(
        self,
        input_texts: Optional[List[str]] = None,
        input_ids: Optional[torch.Tensor] = None,
        attention_mask: Optional[torch.Tensor] = None,
        return_dict: bool = True
    ) -> BERTOutput:
        """
        BERT ëª¨ë¸ ìˆœì „íŒŒ
        
        Args:
            input_texts: ì…ë ¥ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (í† í°í™”ë˜ì§€ ì•Šì€ ì›ì‹œ í…ìŠ¤íŠ¸)
            input_ids: í† í° ID í…ì„œ [batch_size, seq_length]
            attention_mask: ì–´í…ì…˜ ë§ˆìŠ¤í¬ [batch_size, seq_length]
            return_dict: ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜ ì—¬ë¶€
            
        Returns:
            BERTOutput: ëª¨ë¸ ì¶œë ¥ ê²°ê³¼
        """
        start_time = time.time()
        
        # 1. í† í°í™” (í•„ìš”í•œ ê²½ìš°)
        if input_texts is not None:
            tokenization_results = []
            for text in input_texts:
                result = self.tokenizer.tokenize(text)
                tokenization_results.append(result)
            
            # ë°°ì¹˜ë¡œ ë³€í™˜
            input_ids = torch.tensor([r.token_ids for r in tokenization_results])
            attention_mask = torch.tensor([r.attention_mask for r in tokenization_results])
        
        batch_size, seq_length = input_ids.shape
        
        # 2. ì„ë² ë”©
        embedding_result = self.embeddings(input_ids, attention_mask)
        hidden_states = embedding_result.embeddings
        
        # 3. BERT ë ˆì´ì–´ë“¤ í†µê³¼
        all_hidden_states = [hidden_states]
        all_attention_weights = []
        
        for layer in self.layers:
            hidden_states, attention_weights = layer(hidden_states, attention_mask)
            all_hidden_states.append(hidden_states)
            all_attention_weights.append(attention_weights)
        
        # 4. í’€ë§ ([CLS] í† í°ìœ¼ë¡œ ë¬¸ì¥ í‘œí˜„ ìƒì„±)
        pooler_output = self.pooler(hidden_states[:, 0])  # [CLS] í† í°
        
        # 5. ì •ë¶€ ê´€ë ¨ ì˜ˆì¸¡
        government_logits = self.government_classifier(pooler_output)
        recommendation_logits = self.recommendation_classifier(pooler_output)
        
        government_probs = F.softmax(government_logits, dim=-1)
        recommendation_probs = F.softmax(recommendation_logits, dim=-1)
        
        # 6. ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        confidence_scores = self._calculate_confidence_scores(
            hidden_states, attention_mask, government_probs, recommendation_probs
        )
        
        processing_time = time.time() - start_time
        
        # 7. ì •ë¶€ ì˜ˆì¸¡ ê²°ê³¼ ì •ë¦¬
        government_labels = [
            'ì •ì±…ê´€', 'ê³¼ì¥', 'êµ­ì¥', 'ì°¨ê´€', 'ì¥ê´€', 
            'ëŒ€í†µë ¹', 'ì´ë¦¬', 'ë¹„ì„œê´€', 'ë³´ì¢Œê´€', 'ìˆ˜ì„'
        ]
        recommendation_labels = ['ê°•ë ¥ì¶”ì²œ', 'ì¶”ì²œ', 'ë¹„ì¶”ì²œ']
        
        government_predictions = {
            'positions': {label: prob.item() for label, prob in zip(government_labels, government_probs[0])},
            'recommendation': {label: prob.item() for label, prob in zip(recommendation_labels, recommendation_probs[0])}
        }
        
        return BERTOutput(
            last_hidden_state=hidden_states,
            pooler_output=pooler_output,
            attention_weights=all_attention_weights,
            hidden_states=all_hidden_states,
            processing_time=processing_time,
            confidence_scores=confidence_scores,
            government_predictions=government_predictions
        )
    
    def _calculate_confidence_scores(
        self,
        hidden_states: torch.Tensor,
        attention_mask: torch.Tensor,
        government_probs: torch.Tensor,
        recommendation_probs: torch.Tensor
    ) -> Dict[str, float]:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        with torch.no_grad():
            # 1. ì˜ˆì¸¡ ì‹ ë¢°ë„ (ìµœëŒ€ í™•ë¥ ê°’ ê¸°ë°˜)
            gov_confidence = government_probs.max(dim=-1)[0].mean().item()
            rec_confidence = recommendation_probs.max(dim=-1)[0].mean().item()
            
            # 2. ì–´í…ì…˜ ì¼ê´€ì„± (ì–´í…ì…˜ ë¶„í¬ì˜ ì—”íŠ¸ë¡œí”¼)
            attention_consistency = 0.0
            
            # 3. ìˆ¨ê²¨ì§„ ìƒíƒœì˜ ì•ˆì •ì„±
            hidden_stability = 1.0 - hidden_states.std(dim=1).mean().item()
            
            # 4. í† í° í’ˆì§ˆ (UNK í† í° ë¹„ìœ¨)
            token_quality = 1.0  # ê°„ë‹¨íˆ 1.0ìœ¼ë¡œ ì„¤ì •
            
            return {
                'government_confidence': gov_confidence,
                'recommendation_confidence': rec_confidence,
                'attention_consistency': attention_consistency,
                'hidden_stability': hidden_stability,
                'token_quality': token_quality,
                'overall_confidence': (gov_confidence + rec_confidence + hidden_stability + token_quality) / 4.0
            }

class ReliableBERT(nn.Module):
    """
    ğŸ›¡ï¸ ì‹ ë¢°ì„± í–¥ìƒ BERT
    ë‹¤ì¤‘ ê²€ì¦ê³¼ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”ë¥¼ í†µí•œ ì•ˆì •ì ì¸ ì˜ˆì¸¡
    """
    
    def __init__(self, base_model: FastBERT, num_ensemble: int = 3):
        super().__init__()
        
        self.base_model = base_model
        self.num_ensemble = num_ensemble
        
        # ì•™ìƒë¸”ì„ ìœ„í•œ ë‹¤ì¤‘ ëª¨ë¸ (ê°€ì¤‘ì¹˜ ê³µìœ í•˜ì§€ë§Œ ë“œë¡­ì•„ì›ƒ íŒ¨í„´ ë‹¤ë¦„)
        self.ensemble_models = nn.ModuleList([
            self._create_ensemble_model() for _ in range(num_ensemble)
        ])
        
        # ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”ë¥¼ ìœ„í•œ ë² ì´ì§€ì•ˆ í—¤ë“œ
        self.uncertainty_head = nn.Sequential(
            nn.Linear(base_model.config['d_model'], 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 2)  # í‰ê· ê³¼ ë¶„ì‚° ì˜ˆì¸¡
        )
        
        logger.info(f"ğŸ›¡ï¸ ReliableBERT ì´ˆê¸°í™” - ì•™ìƒë¸” í¬ê¸°: {num_ensemble}")
    
    def _create_ensemble_model(self) -> nn.Module:
        """ì•™ìƒë¸”ìš© ëª¨ë¸ ìƒì„± (ë“œë¡­ì•„ì›ƒ íŒ¨í„´ë§Œ ë‹¤ë¦„)"""
        return nn.Sequential(
            nn.Dropout(0.2),  # ë‹¤ë¥¸ ë“œë¡­ì•„ì í™•ë¥ 
            nn.Linear(self.base_model.config['d_model'], self.base_model.config['d_model']),
            nn.ReLU()
        )
    
    def forward(
        self,
        input_texts: Optional[List[str]] = None,
        input_ids: Optional[torch.Tensor] = None,
        attention_mask: Optional[torch.Tensor] = None,
        return_uncertainty: bool = True
    ) -> Dict[str, Any]:
        """
        ì‹ ë¢°ì„± í–¥ìƒëœ ìˆœì „íŒŒ
        
        Args:
            input_texts: ì…ë ¥ í…ìŠ¤íŠ¸
            input_ids: í† í° ID
            attention_mask: ì–´í…ì…˜ ë§ˆìŠ¤í¬
            return_uncertainty: ë¶ˆí™•ì‹¤ì„± ì •ë³´ ë°˜í™˜ ì—¬ë¶€
            
        Returns:
            ì‹ ë¢°ì„± ë¶„ì„ì´ í¬í•¨ëœ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        
        # 1. ê¸°ë³¸ ëª¨ë¸ ì˜ˆì¸¡
        base_output = self.base_model(input_texts, input_ids, attention_mask)
        
        # 2. ì•™ìƒë¸” ì˜ˆì¸¡
        ensemble_outputs = []
        for ensemble_model in self.ensemble_models:
            # ë™ì¼í•œ ì…ë ¥ìœ¼ë¡œ ì—¬ëŸ¬ ë²ˆ ì˜ˆì¸¡ (ë“œë¡­ì•„ì›ƒìœ¼ë¡œ ì¸í•œ ë³€ë™ì„± í™œìš©)
            ensemble_output = self.base_model(input_texts, input_ids, attention_mask)
            ensemble_outputs.append(ensemble_output)
        
        # 3. ì•™ìƒë¸” ê²°ê³¼ í†µí•©
        ensemble_predictions = self._aggregate_ensemble_predictions(ensemble_outputs)
        
        # 4. ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
        uncertainty_scores = None
        if return_uncertainty:
            uncertainty_scores = self._calculate_uncertainty(
                base_output, ensemble_outputs
            )
        
        # 5. ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
        final_confidence = self._calculate_final_confidence(
            base_output, ensemble_predictions, uncertainty_scores
        )
        
        processing_time = time.time() - start_time
        
        return {
            'base_prediction': base_output,
            'ensemble_predictions': ensemble_predictions,
            'uncertainty_scores': uncertainty_scores,
            'final_confidence': final_confidence,
            'processing_time': processing_time,
            'recommendation': self._make_final_recommendation(
                base_output, ensemble_predictions, final_confidence
            )
        }
    
    def _aggregate_ensemble_predictions(self, ensemble_outputs: List[BERTOutput]) -> Dict[str, Any]:
        """ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼ í†µí•©"""
        # ì •ë¶€ ì§ì±… ì˜ˆì¸¡ í‰ê· 
        position_probs = []
        recommendation_probs = []
        
        for output in ensemble_outputs:
            if output.government_predictions:
                position_probs.append(list(output.government_predictions['positions'].values()))
                recommendation_probs.append(list(output.government_predictions['recommendation'].values()))
        
        if position_probs:
            avg_position_probs = np.mean(position_probs, axis=0)
            avg_recommendation_probs = np.mean(recommendation_probs, axis=0)
            
            position_labels = list(ensemble_outputs[0].government_predictions['positions'].keys())
            recommendation_labels = list(ensemble_outputs[0].government_predictions['recommendation'].keys())
            
            return {
                'positions': {label: prob for label, prob in zip(position_labels, avg_position_probs)},
                'recommendation': {label: prob for label, prob in zip(recommendation_labels, avg_recommendation_probs)},
                'position_std': np.std(position_probs, axis=0).tolist(),
                'recommendation_std': np.std(recommendation_probs, axis=0).tolist()
            }
        
        return {}
    
    def _calculate_uncertainty(self, base_output: BERTOutput, ensemble_outputs: List[BERTOutput]) -> Dict[str, float]:
        """ë¶ˆí™•ì‹¤ì„± ì ìˆ˜ ê³„ì‚°"""
        # ì˜ˆì¸¡ ë¶„ì‚° ê³„ì‚°
        predictions = []
        for output in ensemble_outputs:
            if output.government_predictions:
                predictions.append(list(output.government_predictions['positions'].values()))
        
        if predictions:
            prediction_variance = np.var(predictions, axis=0).mean()
            prediction_entropy = -np.sum([p * np.log(p + 1e-8) for p in np.mean(predictions, axis=0)])
            
            return {
                'prediction_variance': prediction_variance,
                'prediction_entropy': prediction_entropy,
                'ensemble_disagreement': prediction_variance,
                'epistemic_uncertainty': prediction_entropy
            }
        
        return {'prediction_variance': 0.0, 'prediction_entropy': 0.0}
    
    def _calculate_final_confidence(
        self, 
        base_output: BERTOutput, 
        ensemble_predictions: Dict[str, Any],
        uncertainty_scores: Optional[Dict[str, float]]
    ) -> Dict[str, float]:
        """ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°"""
        base_confidence = base_output.confidence_scores['overall_confidence']
        
        # ì•™ìƒë¸” ì¼ê´€ì„± ì ìˆ˜
        ensemble_consistency = 1.0
        if ensemble_predictions and 'position_std' in ensemble_predictions:
            ensemble_consistency = 1.0 - np.mean(ensemble_predictions['position_std'])
        
        # ë¶ˆí™•ì‹¤ì„± íŒ¨ë„í‹°
        uncertainty_penalty = 0.0
        if uncertainty_scores:
            uncertainty_penalty = uncertainty_scores.get('prediction_variance', 0.0)
        
        final_confidence = base_confidence * ensemble_consistency * (1.0 - uncertainty_penalty)
        
        return {
            'base_confidence': base_confidence,
            'ensemble_consistency': ensemble_consistency,
            'uncertainty_penalty': uncertainty_penalty,
            'final_confidence': max(0.0, min(1.0, final_confidence))
        }
    
    def _make_final_recommendation(
        self, 
        base_output: BERTOutput, 
        ensemble_predictions: Dict[str, Any],
        final_confidence: Dict[str, float]
    ) -> Dict[str, Any]:
        """ìµœì¢… ì¶”ì²œ ê²°ì •"""
        confidence_threshold = 0.7  # ì‹ ë¢°ë„ ì„ê³„ê°’
        
        is_reliable = final_confidence['final_confidence'] >= confidence_threshold
        
        # ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ì§ì±…ê³¼ ì¶”ì²œë„
        if ensemble_predictions and 'positions' in ensemble_predictions:
            best_position = max(ensemble_predictions['positions'].items(), key=lambda x: x[1])
            best_recommendation = max(ensemble_predictions['recommendation'].items(), key=lambda x: x[1])
            
            return {
                'is_reliable': is_reliable,
                'recommended_position': best_position[0],
                'position_confidence': best_position[1],
                'recommendation_type': best_recommendation[0],
                'recommendation_confidence': best_recommendation[1],
                'overall_confidence': final_confidence['final_confidence'],
                'decision': 'ACCEPT' if is_reliable and best_recommendation[0] in ['ê°•ë ¥ì¶”ì²œ', 'ì¶”ì²œ'] else 'REVIEW'
            }
        
        return {
            'is_reliable': False,
            'decision': 'INSUFFICIENT_DATA'
        }

# í…ŒìŠ¤íŠ¸ ë° ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("ğŸ§  TRAS BERT ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # FastBERT í…ŒìŠ¤íŠ¸
    print("âš¡ FastBERT í…ŒìŠ¤íŠ¸")
    fast_bert = FastBERT(vocab_size=1000, d_model=256, num_layers=4, num_heads=8)
    
    test_texts = [
        "ê¹€ì² ìˆ˜ë¥¼ AI ì •ì±…ê´€ìœ¼ë¡œ ê°•ë ¥íˆ ì¶”ì²œí•©ë‹ˆë‹¤",
        "ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ ì •ë¶€ ì‹œìŠ¤í…œ ê°œë°œì— ê¸°ì—¬í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤"
    ]
    
    # FastBERT ì˜ˆì¸¡
    fast_result = fast_bert(input_texts=test_texts)
    print(f"âœ… FastBERT ì¶œë ¥ í˜•íƒœ: {fast_result.last_hidden_state.shape}")
    print(f"âš¡ ì²˜ë¦¬ ì‹œê°„: {fast_result.processing_time:.4f}ì´ˆ")
    print(f"ğŸ¯ ì „ì²´ ì‹ ë¢°ë„: {fast_result.confidence_scores['overall_confidence']:.3f}")
    
    if fast_result.government_predictions:
        print("ğŸ›ï¸ ì •ë¶€ ì˜ˆì¸¡ ê²°ê³¼:")
        for pos, prob in fast_result.government_predictions['positions'].items():
            if prob > 0.1:  # 10% ì´ìƒë§Œ í‘œì‹œ
                print(f"   {pos}: {prob:.3f}")
    
    # ReliableBERT í…ŒìŠ¤íŠ¸
    print(f"\nğŸ›¡ï¸ ReliableBERT í…ŒìŠ¤íŠ¸")
    reliable_bert = ReliableBERT(fast_bert, num_ensemble=2)
    
    reliable_result = reliable_bert(input_texts=test_texts)
    print(f"âœ… ReliableBERT ì²˜ë¦¬ ì‹œê°„: {reliable_result['processing_time']:.4f}ì´ˆ")
    print(f"ğŸ¯ ìµœì¢… ì‹ ë¢°ë„: {reliable_result['final_confidence']['final_confidence']:.3f}")
    print(f"ğŸ† ìµœì¢… ì¶”ì²œ: {reliable_result['recommendation']['decision']}")
    
    print("\nğŸ‰ BERT ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!") 