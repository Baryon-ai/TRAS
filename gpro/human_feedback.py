#!/usr/bin/env python3
"""
ğŸ‘¥ Human Feedback Simulator: Government Expert Feedback Simulation

Simulates realistic human expert feedback patterns for GPRO training.
"""

import random
import json
import logging
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime
import numpy as np

logger = logging.getLogger(__name__)


@dataclass
class FeedbackData:
    """ì¸ê°„ í”¼ë“œë°± ë°ì´í„° í´ë˜ìŠ¤"""
    expert_id: str
    expert_type: str
    candidate_info: str
    position: str
    preferred_response: str
    rejected_response: str
    preference_strength: float
    reasoning: str
    confidence: float
    timestamp: str
    bias_factors: Dict[str, float]


class HumanFeedbackSimulator:
    """ì¸ê°„ ì „ë¬¸ê°€ í”¼ë“œë°± ì‹œë®¬ë ˆì´í„°"""
    
    def __init__(self, random_seed: int = 42):
        random.seed(random_seed)
        np.random.seed(random_seed)
        
        # ì „ë¬¸ê°€ í”„ë¡œí•„ë“¤
        self.expert_profiles = {
            "hr_specialist_1": {
                "name": "ë°•ì¸ì‚¬",
                "expertise": "ì¸ì‚¬ê´€ë¦¬",
                "experience_years": 15,
                "preferences": {
                    "fairness_weight": 0.9,
                    "process_weight": 0.8,
                    "diversity_weight": 0.7,
                    "consistency_weight": 0.85
                },
                "bias_tendencies": {
                    "experience_bias": 0.2,
                    "education_bias": 0.15,
                    "stability_bias": 0.25
                }
            },
            "tech_expert_1": {
                "name": "ì´ê¸°ìˆ ",
                "expertise": "ê¸°ìˆ í‰ê°€",
                "experience_years": 12,
                "preferences": {
                    "technical_weight": 0.95,
                    "innovation_weight": 0.8,
                    "problem_solving_weight": 0.85,
                    "learning_weight": 0.75
                },
                "bias_tendencies": {
                    "tech_company_bias": 0.3,
                    "publication_bias": 0.4,
                    "trend_bias": 0.2
                }
            }
        }
        
        logger.info("ì¸ê°„ í”¼ë“œë°± ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def generate_expert_feedback(
        self, 
        candidate_info: str,
        position: str,
        ai_recommendation: Dict,
        expert_id: str = None
    ) -> FeedbackData:
        """ì „ë¬¸ê°€ í”¼ë“œë°± ìƒì„±"""
        if expert_id is None:
            expert_id = random.choice(list(self.expert_profiles.keys()))
        
        expert = self.expert_profiles[expert_id]
        
        # í›„ë³´ì íŠ¹ì„± ë¶„ì„
        candidate_features = self._analyze_candidate(candidate_info)
        
        # ì „ë¬¸ê°€ í‰ê°€
        expert_evaluation = self._evaluate_from_expert_perspective(
            candidate_features, position, expert, ai_recommendation
        )
        
        # ì„ í˜¸ë„ ìŒ ìƒì„±
        preferred, rejected = self._generate_preference_pair(
            expert_evaluation, ai_recommendation, expert
        )
        
        return FeedbackData(
            expert_id=expert_id,
            expert_type=expert["expertise"],
            candidate_info=candidate_info,
            position=position,
            preferred_response=preferred,
            rejected_response=rejected,
            preference_strength=expert_evaluation["preference_strength"],
            reasoning=expert_evaluation["reasoning"],
            confidence=expert_evaluation["confidence"],
            timestamp=datetime.now().isoformat(),
            bias_factors=expert_evaluation["bias_factors"]
        )
    
    def _analyze_candidate(self, candidate_info: str) -> Dict:
        """í›„ë³´ì ì •ë³´ ë¶„ì„"""
        features = {
            "education_level": 0.5,
            "experience_years": 0.5,
            "technical_skills": 0.5,
            "leadership_exp": 0.5,
            "government_exp": 0.5,
            "publication_count": 0.5
        }
        
        text = candidate_info.lower()
        
        # êµìœ¡ ìˆ˜ì¤€
        if "ë°•ì‚¬" in text:
            features["education_level"] = 0.9
        elif "ì„ì‚¬" in text:
            features["education_level"] = 0.7
        
        # ê¸°ìˆ  í‚¤ì›Œë“œ
        tech_keywords = ["ai", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "ë°ì´í„°"]
        tech_count = sum(1 for keyword in tech_keywords if keyword in text)
        features["technical_skills"] = min(tech_count / len(tech_keywords), 1.0)
        
        # ë¦¬ë”ì‹­ ê²½í—˜
        if any(word in text for word in ["íŒ€ì¥", "ë¦¬ë”", "ê´€ë¦¬"]):
            features["leadership_exp"] = 0.8
        
        # ì •ë¶€ ê²½í—˜
        if any(word in text for word in ["ì •ë¶€", "ìë¬¸", "ìœ„ì›íšŒ"]):
            features["government_exp"] = 0.7
        
        return features
    
    def _evaluate_from_expert_perspective(
        self, 
        candidate_features: Dict,
        position: str,
        expert: Dict,
        ai_recommendation: Dict
    ) -> Dict:
        """ì „ë¬¸ê°€ ê´€ì  í‰ê°€"""
        # ê°„ë‹¨í•œ ì ìˆ˜ ê³„ì‚°
        expert_score = sum(candidate_features.values()) / len(candidate_features)
        ai_score = ai_recommendation.get("confidence", 0.5)
        
        score_diff = abs(expert_score - ai_score)
        preference_strength = min(score_diff * 2.0, 1.0)
        
        confidence = min(expert["experience_years"] / 20.0, 0.95)
        
        reasoning = f"ì „ë¬¸ê°€ ê´€ì ì—ì„œ ì¢…í•© ì ìˆ˜ {expert_score:.2f}ë¡œ í‰ê°€"
        
        return {
            "expert_score": expert_score,
            "ai_score": ai_score,
            "preference_strength": preference_strength,
            "confidence": confidence,
            "reasoning": reasoning,
            "bias_factors": expert["bias_tendencies"]
        }
    
    def _generate_preference_pair(
        self, 
        expert_evaluation: Dict,
        ai_recommendation: Dict,
        expert: Dict
    ) -> Tuple[str, str]:
        """ì„ í˜¸ë„ ìŒ ìƒì„±"""
        expert_score = expert_evaluation["expert_score"]
        
        if expert_score >= 0.7:
            expert_recommendation = "ì¶”ì²œ"
        elif expert_score >= 0.5:
            expert_recommendation = "ë³´ë¥˜"
        else:
            expert_recommendation = "ë¹„ì¶”ì²œ"
        
        preferred = f"ì´ í›„ë³´ìë¥¼ {expert_recommendation}í•©ë‹ˆë‹¤. {expert_evaluation['reasoning']}"
        rejected = f"ì´ í›„ë³´ìì— ëŒ€í•œ ë‹¤ë¥¸ í‰ê°€ëŠ” ë¶€ì ì ˆí•©ë‹ˆë‹¤."
        
        return preferred, rejected


def create_sample_candidates() -> List[Dict]:
    """ìƒ˜í”Œ í›„ë³´ì ìƒì„±"""
    return [
        {
            "info": "ê¹€AIëŠ” ì„œìš¸ëŒ€ ë°•ì‚¬ë¡œ êµ¬ê¸€ì—ì„œ 5ë…„ ê·¼ë¬´í–ˆìŠµë‹ˆë‹¤.",
            "position": "AIì •ì±…ê´€"
        }
    ]


if __name__ == "__main__":
    print("ğŸ‘¥ Human Feedback Simulator í…ŒìŠ¤íŠ¸")
    
    simulator = HumanFeedbackSimulator()
    
    test_candidate = "ê¹€ì² ìˆ˜ëŠ” ì„œìš¸ëŒ€ ë°•ì‚¬ë¡œ êµ¬ê¸€ì—ì„œ AI ì—°êµ¬ë¥¼ í–ˆìŠµë‹ˆë‹¤."
    test_ai_recommendation = {
        'prediction': 'ì¶”ì²œ',
        'confidence': 0.85
    }
    
    feedback = simulator.generate_expert_feedback(
        test_candidate, "AIì •ì±…ê´€", test_ai_recommendation
    )
    
    print(f"ì „ë¬¸ê°€: {feedback.expert_id}")
    print(f"ì„ í˜¸ë„: {feedback.preference_strength:.3f}")
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!") 